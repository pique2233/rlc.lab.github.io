<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Directions</title>
    <link rel="stylesheet" href="css/Direction.css">
    <style>

    </style>
</head>
<body>
    <div class="container">
        <!-- Header Section -->
        <header>
            <div class="logo">
                <h1>RLC</h1>
                <p>Robotic AI & Learning Lab</p>
                <p><a href="#">@ BAIR</a></p>
            </div>
            <!-- Navigation Links -->
            <nav>
                <ul>
                    <li><a href="Home.html">home</a></li>
                    <li><a href="People2.html">people</a></li>
                    <li><a href="Direction.html"class="active">direction</a></li>
                    <li><a href="Activity.html">activity</a></li>
                    <li><a href="Contact.html" >contact</a></li>
                </ul>
            </nav>
        </header>

        <!-- Main Formal Method Image -->
        <section class="hero">
            <img src="./picture/formal.jpg" alt="Formal Method Image" class="hero-image">
        </section>

        <!-- Research Section -->
        <section class="research-section">
            <h1>Research Directions</h1>

            <!-- Research Direction: RL -->
            <div class="research-category">
                <h2>Reinforcement Learning (RL)</h2>
                <p class="research-description">
                    We explore advanced reinforcement learning techniques that allow machines to learn optimal actions through trial and error in dynamic environments.
                </p>
                <div class="research-images">
                    <img src="./picture/机械狗.jpg" alt="RL Image 1">
                    <img src="./picture/机械臂.jpg" alt="RL Image 2">
                    <img src="rl_image3.jpg" alt="RL Image 3">
                </div>
            </div>

            <!-- Research Direction: Offline RL -->
            <div class="research-category">
                <h2>Offline Reinforcement Learning</h2>
                <p class="research-description">
                    Our work in offline RL focuses on improving the performance of agents using previously collected data, without the need for real-time interaction with the environment.
                </p>
                <div class="research-images">
                    <img src="./picture/offlinerl.jpg" alt="Offline RL Image 1">
                    <img src="offline_rl_image2.jpg" alt="Offline RL Image 2">
                    <img src="offline_rl_image3.jpg" alt="Offline RL Image 3">
                </div>
            </div>

            <!-- Research Direction: Diffusion Policy -->
            <div class="research-category">
                <h2>Diffusion Policy</h2>
                <p class="research-description">
                    Diffusion policies enable learning policies in high-dimensional spaces, which are particularly useful for complex decision-making tasks in robotics.
                </p>
                <div class="research-images">
                    <img src="diffusion_policy_image1.jpg" alt="Diffusion Policy Image 1">
                    <img src="diffusion_policy_image2.jpg" alt="Diffusion Policy Image 2">
                </div>
            </div>

            <!-- Research Direction: Decision Transformer -->
            <div class="research-category">
                <h2>Decision Transformer</h2>
                <p class="research-description">
                    We utilize decision transformers to process sequential decision-making problems, enabling efficient planning and control for a wide variety of tasks.
                </p>
                <div class="research-images">
                    <img src="decision_transformer_image1.jpg" alt="Decision Transformer Image 1">
                    <img src="decision_transformer_image2.jpg" alt="Decision Transformer Image 2">
                </div>
            </div>

            <!-- Simulation and Physical Entity Section -->
            <div class="research-category">
                <h2>Simulation and Physical Entities</h2>
                <p class="research-description">
                    Our simulation environments and physical systems bridge the gap between theoretical research and real-world applications, allowing us to test and validate our models effectively.
                </p>
                <div class="research-images">
                    <img src="./picture/Gazebo.jpg" alt="Simulation Image 1">
                    <img src="./picture/" alt="Simulation Image 2">
                    <img src="./picture/无人机.jpg" alt="Simulation Image 3">
                    <img src="./picture/car.jpg" alt="Physical Entity Image 1">
                    <img src="./picture/car2.jpg" alt="Physical Entity Image 2">
                </div>
            </div>
        </section>

        <!-- Footer Section -->
        <footer>
            <hr>
            <p>Copyright © UC Berkeley RAIL Lab 2024</p>
            <p>Contact: <a href="mailto:contact@raillab.berkeley.edu">contact@raillab.berkeley.edu</a></p>
        </footer>
    </div>
</body>
</html>
